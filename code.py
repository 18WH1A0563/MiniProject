# -*- coding: utf-8 -*-
"""LDD.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1dq02pkdWoBUCBI6TXib3lhAK9Czi5Erl
"""

import os
import numpy as np
import glob
import matplotlib.pyplot as plt
import keras 
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers import Dropout
from tensorflow.keras.optimizers import Adam
from keras.layers import Activation,AveragePooling2D,BatchNormalization
from keras.preprocessing.image import ImageDataGenerator

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/MyDrive/ML_Project/LeafDisease.zip"

base_dir = os.path.join(os.getcwd(), 'LeafDisease')
base_dir0= os.path.join(base_dir, 'New Plant Diseases Dataset(Augmented)')
base_dir1= os.path.join(base_dir0, 'New Plant Diseases Dataset(Augmented)')
train_dir = os.path.join(base_dir1, 'train')
validation_dir = os.path.join(base_dir1, 'valid')

def get_files(directory):
  if not os.path.exists(directory):
    return 0
  count=0
  for current_path,dirs,files in os.walk(directory):
    for dr in dirs:
      count+= len(glob.glob(os.path.join(current_path,dr+"/*")))
  return count

train_samples =get_files(train_dir)
num_classes=len(glob.glob(train_dir+"/*"))
validation_samples=get_files(validation_dir)
print(num_classes,"Classes")
print(train_samples,"Train images")
print(validation_samples,"validation images")

train_datagen=ImageDataGenerator(rescale=1./255,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   validation_split=0.2, # validation split 20%.
                                   horizontal_flip=True)
test_datagen=ImageDataGenerator(rescale=1./255)

img_width,img_height =256,256
input_shape=(img_width,img_height,3)
batch_size =32

train_generator =train_datagen.flow_from_directory(train_dir,
                                                   target_size=(img_width,img_height),
                                                   batch_size=batch_size)
test_generator=test_datagen.flow_from_directory(validation_dir,shuffle=True,
                                                   target_size=(img_width,img_height),
                                                   batch_size=batch_size)

train_generator.class_indices

model = Sequential()
model.add(Conv2D(32, (5, 5),input_shape=input_shape,activation='relu'))
model.add(MaxPooling2D(pool_size=(3, 3)))
model.add(Conv2D(32, (3, 3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, (3, 3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))   
model.add(Flatten())
model.add(Dense(512,activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(128,activation='relu'))          
model.add(Dense(num_classes,activation='softmax'))
model.summary()

model_layers = [ layer.name for layer in model.layers]
print('layer name : ',model_layers)

validation_generator = train_datagen.flow_from_directory(
    train_dir, # same directory as training data
    target_size=(img_height, img_width),
    batch_size=batch_size)

from tensorflow import keras

opt=keras.optimizers.Adam(lr=0.001)
model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])
train=model.fit_generator(train_generator,
                          epochs=15,
                          steps_per_epoch=train_generator.samples // batch_size,
                          validation_data=validation_generator,
                          validation_steps= validation_generator.samples // batch_size,verbose=1)

acc = train.history['accuracy']
val_acc = train.history['val_accuracy']
loss = train.history['loss']
val_loss = train.history['val_loss']
epochs = range(1, len(acc) + 1)
#Train and validation accuracy
plt.plot(epochs, acc, 'b', label='Training accurarcy')
plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')
plt.title('Training and Validation accurarcy')
plt.legend()

plt.figure()
#Train and validation loss
plt.plot(epochs, loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and Validation loss')
plt.legend()
plt.show()

from keras.models import load_model
model.save('CornLDD.h5')
model.save('drive/MyDrive/ML_Project/LDD.model')

from keras.models import load_model
model.save_weights('leaf_weights.h5')

classes = train_generator.class_indices 
classes

from keras.models import load_model
classifier = load_model('drive/MyDrive/ML_Project/LDD.model')

from google.colab import files
uploaded = files.upload()

from tensorflow.keras.preprocessing import image
path = "CornCommonRust1.JPG"
test_image = image.load_img(path)
from matplotlib.pyplot import imshow
plt.imshow(test_image)
test_img = image.load_img(path, target_size=(256,256))
test_img = image.img_to_array(test_img)
test_img = np.expand_dims(test_img,axis=0)
result = classifier.predict(test_img)
a = result.argmax()
s = train_generator.class_indices
name = [ ]
for i in s:
     name.append(i)
for i in range(len(s)):
     if (i==a):
          p=name[i]
p
